---
phase: 02-static-quantization-&-i
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/mono_quant/core/observers.py
  - src/mono_quant/calibration/__init__.py
  - src/mono_quant/calibration/runner.py
  - src/mono_quant/calibration/data.py
  - src/mono_quant/core/__init__.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "User can provide calibration data as List[torch.Tensor] or DataLoader"
    - "Observer tracks min/max values from tensor activations during forward passes"
    - "Calibration runner executes forward passes with optional progress bar for large datasets"
    - "Observer calculates scale and zero-point from observed min/max values"
  artifacts:
    - path: "src/mono_quant/core/observers.py"
      provides: "MinMaxObserver class for tracking activation ranges"
      min_lines: 60
      exports: ["MinMaxObserver"]
    - path: "src/mono_quant/calibration/runner.py"
      provides: "Calibration forward pass execution with progress support"
      min_lines: 80
      exports: ["run_calibration"]
    - path: "src/mono_quant/calibration/data.py"
      provides: "DataLoader and tensor list normalization"
      min_lines: 50
      exports: ["_normalize_calibration_data"]
  key_links:
    - from: "src/mono_quant/calibration/runner.py"
      to: "src/mono_quant/core/observers.py"
      via: "MinMaxObserver.forward() called during calibration"
      pattern: "observer\.forward\(.*tensor"
    - from: "src/mono_quant/calibration/data.py"
      to: "torch.utils.data.DataLoader"
      via: "DataLoader extraction for (input, target) batches"
      pattern: "isinstance.*DataLoader"
---

<objective>
Build calibration infrastructure for static quantization: MinMaxObserver for tracking activation ranges, calibration runner for forward passes with progress reporting, and data normalization for multiple input formats.

Purpose: Static quantization requires observing activation ranges from representative data. This plan provides the observer pattern (custom implementation avoiding deprecated torch.ao.quantization APIs), forward pass execution, and flexible data input handling.

Output: Calibration-ready infrastructure with MinMaxObserver, run_calibration() function, and support for List[torch.Tensor] or DataLoader inputs.
</objective>

<execution_context>
@C:\Users\ghost\.thatAverageGuy\get-shit-done\workflows\execute-plan.md
@C:\Users\ghost\.thatAverageGuy\get-shit-done\templates\summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-static-quantization-&-i/02-CONTEXT.md
@.planning/phases/02-static-quantization-&-i/02-RESEARCH.md
@.planning/phases/01-core-quantization-foundation/01-04-SUMMARY.md

# Context from Phase 1
- Existing: src/mono_quant/core/quantizers.py (dynamic_quantize, weight quantization)
- Existing: src/mono_quant/io/handlers.py (_prepare_model for copying)
- Pattern: Local imports to avoid circular dependencies
- Pattern: Underscore prefix for internal functions
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create MinMaxObserver</name>
  <files>src/mono_quant/core/observers.py</files>
  <action>
Create MinMaxObserver class in src/mono_quant/core/observers.py with:

1. __init__(self, dtype: torch.dtype = torch.qint8)
   - Store dtype, initialize min_val=None, max_val=None

2. forward(self, x: torch.Tensor) -> None
   - Update min_val = min(min_val, x.amin().item())
   - Update max_val = max(max_val, x.amax().item())
   - Handle first call when min_val/max_val are None

3. calculate_qparams(self) -> Tuple[torch.Tensor, torch.Tensor]
   - Raise RuntimeError if no data observed (min_val is None)
   - Calculate qmin=-128, qmax=127 for int8 range
   - Compute scale = (max_val - min_val) / (qmax - qmin)
   - Clamp scale >= 1e-8 to avoid division by zero
   - Compute zero_point = qmin - (min_val / scale)
   - Convert zero_point to int (round)
   - Return torch.tensor(scale), torch.tensor(zero_point, dtype=torch.int32)

4. reset(self) -> None
   - Reset min_val=None, max_val=None

DO NOT use torch.ao.quantization.MinMaxObserver (deprecated, removal in PyTorch 2.10+).

Add module docstring explaining this is a custom implementation to avoid deprecated APIs.

Add src/mono_quant/core/__init__.py to export MinMaxObserver.
</action>
  <verify>
import mono_quant.core.observers
obs = mono_quant.core.observers.MinMaxObserver()
assert obs.min_val is None
x = torch.randn(32, 64)
obs.forward(x)
assert obs.min_val is not None
scale, zp = obs.calculate_qparams()
assert scale.ndim == 0 and zp.ndim == 0
</verify>
  <done>
MinMaxObserver class tracks min/max from tensor activations and calculates scale/zero-point for quantization. Verified with test forward pass and qparams calculation.
</done>
</task>

<task type="auto">
  <name>Task 2: Create calibration data normalization</name>
  <files>src/mono_quant/calibration/data.py</files>
  <action>
Create calibration data handling in src/mono_quant/calibration/data.py with:

1. Type alias: CalibrationData = Union[List[torch.Tensor], DataLoader]

2. _normalize_calibration_data(data: CalibrationData) -> List[torch.Tensor]
   - If isinstance(data, DataLoader):
     - Iterate over data, extract batches
     - For each batch: if tuple/list, take batch[0] (assume input, target format)
     - Else: take batch as-is
     - Return list of extracted tensors
   - Else (already list): return data directly

3. _limit_samples(tensors: List[torch.Tensor], num_samples: int) -> List[torch.Tensor]
   - Return tensors[:num_samples]
   - Handle case where len(tensors) < num_samples

Add module docstring explaining DataLoader support for (input, target) batching pattern.

Create src/mono_quant/calibration/__init__.py to export _normalize_calibration_data.
</action>
  <verify>
from mono_quant.calibration.data import _normalize_calibration_data
from torch.utils.data import DataLoader

# Test with list
data_list = [torch.randn(10, 20) for _ in range(5)]
result = _normalize_calibration_data(data_list)
assert len(result) == 5

# Test with DataLoader
dataset = data_list
loader = DataLoader(dataset, batch_size=2)
result = _normalize_calibration_data(loader)
assert len(result) == 5  # All batches extracted
</verify>
  <done>
Calibration data normalization supports both List[torch.Tensor] and DataLoader inputs. DataLoader batches are extracted with (input, target) pattern handling.
</done>
</task>

<task type="auto">
  <name>Task 3: Create calibration runner with progress reporting</name>
  <files>src/mono_quant/calibration/runner.py</files>
  <action>
Create calibration runner in src/mono_quant/calibration/runner.py with:

1. run_calibration(
     model: nn.Module,
     calibration_data: CalibrationData,
     observers: Optional[Dict[str, MinMaxObserver]] = None,
     num_samples: int = 150,
     show_progress: Optional[bool] = None
   ) -> Dict[str, MinMaxObserver]

   Implementation:
   - Import MinMaxObserver from mono_quant.core.observers
   - Import _normalize_calibration_data from .data
   - Normalize calibration_data to tensor list
   - Limit to num_samples using _limit_samples
   - Auto-detect show_progress: if None, set True when len(tensors) > 50
   - Set model.eval()
   - Use torch.no_grad() context
   - If show_progress and tqdm available: use tqdm(tensors) as iterator
     - Try import tqdm, if ImportError, show_progress=False
   - For each tensor: _ = model(tensor) to trigger observers
   - If observers is None: create empty dict (observers attached by caller)
   - Return observers dict

2. _auto_detect_progress_threshold(num_samples: int) -> bool
   - Return num_samples > 50 (thatAverageGuy's discretion per CONTEXT.md)

Add module docstring explaining calibration uses 150 samples as default (based on RESEARCH.md recommending 100-200 samples).

Update src/mono_quant/calibration/__init__.py to export run_calibration.
</action>
  <verify>
from mono_quant.calibration.runner import run_calibration
import torch.nn as nn

model = nn.Sequential(nn.Linear(10, 20), nn.ReLU())
data = [torch.randn(4, 10) for _ in range(100)]
observers = run_calibration(model, data, num_samples=50)
assert isinstance(observers, dict)
# Model runs without error (observers can be attached externally)
</verify>
  <done>
Calibration runner executes forward passes with auto-detecting progress bar (tqdm if available, silent threshold at 50 samples). Default 150 samples per research recommendations.
</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. from mono_quant.core.observers import MinMaxObserver - imports successfully
2. from mono_quant.calibration import run_calibration, _normalize_calibration_data - imports successfully
3. MinMaxObserver can observe tensor data and calculate qparams
4. run_calibration executes forward passes without error
5. DataLoader input is properly normalized to tensor list
6. Progress bar shows for >50 samples when tqdm available
</verification>

<success_criteria>
- MinMaxObserver calculates scale and zero-point from observed tensor ranges
- Calibration accepts both List[torch.Tensor] and DataLoader inputs
- run_calibration executes forward passes with optional progress reporting
- 150 sample default aligns with research recommendations (100-200 baseline)
- No deprecated torch.ao.quantization APIs used
</success_criteria>

<output>
After completion, create `.planning/phases/02-static-quantization-&-i/02-01-SUMMARY.md`
</output>
